\chapter{方法、结果、讨论}\label{chap:res}
接下来，我们将对该文章使用的方法、得出的结果，以及该文章的讨论部分进行写作规范方面的分析。
\section{方法}
这篇文章在引言部分，就点出了当前三大主流研究方向——更大的数据集，具有更强大学习能力的模型，更好地处理过拟合的方法。而这三点也是一个神经模型实现的关键。方法部分，作者也是这样组织的。

首先，作者在第二部分数据集中，对模型采用的训练集和测试集进行了详细地介绍——ImageNet。由于本篇文章重点突出，在较大数据集上，如何训练出具有强大学习能力的模型，所以作者在数据集介绍过程中，突出强调ImageNet是一个超大型的高分辨率图像数据集。同时，作者说明了他们在训练过程中观测的重要指标，错误率(top-1和top-5)。另外，作者也描述了他们对数据的预处理，为模型效果复现提供了必要的基础。

方法第三部分便是模型的框架。作者开篇介绍网络共8层——5个卷积层和3个全连接层，这好比是一个具体模型的骨架。在3.1至3.4节中，作者针对模型架构中新颖的特点，按照重要程度，一一进行了介绍。这些好比是依附在骨架上的血肉，而正是这些与前人不同的特点，使得Alexnet2012成为了当时图像分类最好的模型。其中包括非线性ReLU方法，更是成为了今后解决梯度消失问题经典方法。

方法的第四部分则是针对处理过拟合问题的方法，结构与第三部分相似，分条列出两种主要方法——数据增强和Dorpout。
\section{结果}

文章的结果采用报告实验型结果，如表~\ref{tab:tbl1}、表~\ref{tab:tbl2}所示。文章给出了Alexnet模型与其他人（表中的斜体部分）效果最好的模型的Top-1和Top-5错误率，清晰直观地显现出Alexnet模型在图像分类上的优越性。同时，在定量描述之外，作者还对结果进行了定性评估，分析模型在特定数据集上的效果，图文并茂，直观明了。

\section{讨论}
作者在讨论部分对全文进行了总结，在强调模型在具有挑战性的大型数据集上取得破纪录的结果同时，点出了模型的不足之处——模型可以更大，训练时间可以更长。同时提出了新的问题，给阅读者提供了未来新的研究方向——希望在视频序列中使用非常大且深的卷积网络。